{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5-Wc-YXlL8xf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import Vocab, build_vocab_from_iterator, vocab\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from collections import Counter\n",
        "import os\n",
        "import spacy\n",
        "import csv\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eehgd2mMMLbA",
        "outputId": "79e6c9a4-6798-467a-ccc3-f86b3f6137f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-07-21 09:33:17.574855: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-lg==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.5.0) (3.5.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.10.11)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "! spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cnVPEaSEMcW9"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Mmq3im-1Mfqx"
      },
      "outputs": [],
      "source": [
        " ! pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCN7KI3ZMjB-",
        "outputId": "0ae903a6-d74b-44e5-a131-935e67112779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading ubuntu-dialogue-corpus.zip to /content\n",
            "100% 799M/799M [00:20<00:00, 43.7MB/s]\n",
            "100% 799M/799M [00:20<00:00, 40.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"\" # key from the json file\n",
        "!kaggle datasets download -d rtatman/ubuntu-dialogue-corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb1M-WWTPeOB",
        "outputId": "63ce7d53-2b72-41e8-9106-bf95e175b6b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  ubuntu-dialogue-corpus.zip\n",
            "  inflating: Ubuntu-dialogue-corpus/dialogueText.csv  \n",
            "  inflating: Ubuntu-dialogue-corpus/dialogueText_196.csv  \n",
            "  inflating: Ubuntu-dialogue-corpus/dialogueText_301.csv  \n",
            "  inflating: toc.csv                 \n"
          ]
        }
      ],
      "source": [
        "! unzip ubuntu-dialogue-corpus.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qRLn_vq2PAXB"
      },
      "outputs": [],
      "source": [
        "\n",
        "def question_tokenizer(text):\n",
        "    return [token.text.strip().lower() for token in nlp.tokenizer(text) if not token.is_punct and token.text.strip() != '']\n",
        "\n",
        "def answer_tokenizer(text):\n",
        "    return [token.text.strip().lower() for token in nlp.tokenizer(text) if not token.is_punct and token.text.strip() != '']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-qrovthhHB1R"
      },
      "outputs": [],
      "source": [
        "\n",
        "question_answer_pairs = []\n",
        "with open('Ubuntu-dialogue-corpus/dialogueText.csv', newline='') as csvfile:\n",
        "    dialogue = csv.reader(csvfile)\n",
        "    question = ''\n",
        "    answer = ''\n",
        "    previous_frm = 'Na'\n",
        "    previous_to = 'Na'\n",
        "    for idx, row in enumerate(dialogue):\n",
        "      # skip the first row\n",
        "      if idx ==0:\n",
        "        continue\n",
        "\n",
        "\n",
        "      frm = row[3]\n",
        "      to = row[4]\n",
        "      text = row[5]\n",
        "\n",
        "      #TODO this logic doesn't account for multiple answers to the samae question\n",
        "\n",
        "      # if the text is to the previous from it's an answer\n",
        "      if to == previous_frm:\n",
        "        answer += f' {text}'\n",
        "      # if the from and to are still the same it's the sam question\n",
        "      elif frm == previous_frm and to == previous_to:\n",
        "        #question += f' {text}'\n",
        "        question = text\n",
        "      # if the from or to are different we assume it's a new question\n",
        "      elif frm != previous_frm or to != previous_to:\n",
        "        # if the previous question got an answer add it\n",
        "\n",
        "        if answer and len(question.split(' ')) < 20:\n",
        "          question_answer_pairs.append((question, answer))\n",
        "        question = text\n",
        "        answer = ''\n",
        "      else:\n",
        "        raise ValueError(f'unknown state: {frm} - {to} - {previous_frm} -- {previous_to}')\n",
        "\n",
        "      previous_frm = frm\n",
        "      previous_to = to\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "TCpgpipCcdah"
      },
      "outputs": [],
      "source": [
        "len(question_answer_pairs)\n",
        "#question_answer_pairs = question_answer_pairs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6riutofYLwhf"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def question_iter():\n",
        "  for question, _ in question_answer_pairs:\n",
        "    yield question_tokenizer(question)\n",
        "\n",
        "def answer_iter():\n",
        "  for _, answer in question_answer_pairs:\n",
        "    yield answer_tokenizer(answer)\n",
        "\n",
        "vocab_q = build_vocab_from_iterator(question_iter(), specials=['<pad>','<bos>','<eos>'])\n",
        "vocab_a = build_vocab_from_iterator(answer_iter(), specials=['<pad>','<bos>','<eos>'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "VBhXI7ELHsr8"
      },
      "outputs": [],
      "source": [
        "# different way to build vocab.\n",
        "def build_vocab():\n",
        "  counter_q = Counter()\n",
        "  counter_a = Counter()\n",
        "  for question, answer in question_answer_pairs:\n",
        "      counter_q.update(question_tokenizer(question))\n",
        "      counter_a.update(answer_tokenizer(answer))\n",
        "  return vocab(counter_q, specials=['<unk>', '<pad>', '<bos>', '<eos>']), vocab(counter_a, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
        "\n",
        "\n",
        "vocab_q, vocab_a = build_vocab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se8Oybg9t-Ih",
        "outputId": "d607630b-71a3-4ddc-a37a-ada6faa7d9fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_a['<eos>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X58rFQxinnUD",
        "outputId": "3172cfb1-edc9-4656-a392-420a04731648"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(vocab_q.get_stoi().values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pYm_RpomKgJM"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "for question, answer in question_answer_pairs:\n",
        "  question_tensor_ = torch.tensor([vocab_q[token] for token in question_tokenizer(question)],\n",
        "                            dtype=torch.long)\n",
        "  answer_tensor_ = torch.tensor([vocab_a[token] for token in answer_tokenizer(answer)],\n",
        "                            dtype=torch.long)\n",
        "  data.append((question_tensor_, answer_tensor_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ASWpoP6yUvi",
        "outputId": "b5e4763c-aedc-4a7d-889e-a01ecdf33d87"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Wdk3jw1XKnEY"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#device = torch.device('cpu')\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "PAD_IDX = vocab_a['<pad>']\n",
        "BOS_IDX = vocab_a['<bos>']\n",
        "EOS_IDX = vocab_a['<eos>']\n",
        "\n",
        "def generate_batch(data_batch):\n",
        "  batch_question, batch_answer = [], []\n",
        "  for question, answer in data_batch:\n",
        "    batch_answer.append(torch.cat([torch.tensor([BOS_IDX]), answer, torch.tensor([EOS_IDX])], dim=0))\n",
        "    batch_question.append(torch.cat([torch.tensor([BOS_IDX]), question, torch.tensor([EOS_IDX])], dim=0))\n",
        "  batch_answer = pad_sequence(batch_answer, padding_value=PAD_IDX)\n",
        "  batch_question = pad_sequence(batch_question, padding_value=PAD_IDX)\n",
        "  return batch_question, batch_answer\n",
        "\n",
        "train_idx, test_idx = train_test_split(list(range(len(data))), test_size=0.1)\n",
        "train_idx, val_idx = train_test_split(train_idx, test_size=0.1)\n",
        "\n",
        "\n",
        "train_iter = DataLoader(Subset(data, train_idx), batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)\n",
        "test_iter = DataLoader(Subset(data, test_idx), batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)\n",
        "val_iter = DataLoader(Subset(data, val_idx), batch_size=BATCH_SIZE, shuffle=False, collate_fn=generate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "gtnto64ztxmB"
      },
      "outputs": [],
      "source": [
        "_, value = next(enumerate(train_iter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETTfUM7puChS",
        "outputId": "0fdb753f-3dbc-4aba-8d69-26b412d4022a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<bos>',\n",
              " 'how',\n",
              " 'do',\n",
              " 'i',\n",
              " 'install',\n",
              " '.deb',\n",
              " 'files',\n",
              " 'too',\n",
              " '<eos>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>']"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_q.lookup_tokens([i[0].item() for i in value[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17lptpX8u-UL",
        "outputId": "5a314445-cf02-491d-a999-cc880af4de19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<bos>',\n",
              " 'search',\n",
              " 'automatrix',\n",
              " 'on',\n",
              " 'the',\n",
              " 'forums',\n",
              " '<eos>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>']"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_a.lookup_tokens([i[0].item() for i in value[1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NACYK9dND1T",
        "outputId": "30b0eecd-e514-4bfd-d364-f1ff00881548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The model has 20,206,144 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "from binascii import Error\n",
        "import random\n",
        "from typing import Tuple\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim: int,\n",
        "                 emb_dim: int,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 dropout: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor) -> Tuple[Tensor]:\n",
        "        try:\n",
        "          embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "          outputs, hidden = self.rnn(embedded)\n",
        "\n",
        "          hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "\n",
        "          return outputs, hidden\n",
        "        except Error as e:\n",
        "          print(e)\n",
        "          raise\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 attn_dim: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "\n",
        "        self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n",
        "\n",
        "        self.attn = nn.Linear(self.attn_in, attn_dim)\n",
        "\n",
        "    def forward(self,\n",
        "                decoder_hidden: Tensor,\n",
        "                encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((\n",
        "            repeated_decoder_hidden,\n",
        "            encoder_outputs),\n",
        "            dim = 2)))\n",
        "\n",
        "        attention = torch.sum(energy, dim=2)\n",
        "\n",
        "        return F.softmax(attention, dim=1)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 output_dim: int,\n",
        "                 emb_dim: int,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 dropout: int,\n",
        "                 attention: nn.Module):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "\n",
        "        self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def _weighted_encoder_rep(self,\n",
        "                              decoder_hidden: Tensor,\n",
        "                              encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        a = self.attention(decoder_hidden, encoder_outputs)\n",
        "\n",
        "        a = a.unsqueeze(1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
        "\n",
        "        weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n",
        "\n",
        "        return weighted_encoder_rep\n",
        "\n",
        "\n",
        "    def forward(self,\n",
        "                input: Tensor,\n",
        "                decoder_hidden: Tensor,\n",
        "                encoder_outputs: Tensor) -> Tuple[Tensor]:\n",
        "\n",
        "        input = input.unsqueeze(0)\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden,\n",
        "                                                          encoder_outputs)\n",
        "\n",
        "        rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n",
        "\n",
        "        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n",
        "\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
        "\n",
        "        output = self.out(torch.cat((output,\n",
        "                                     weighted_encoder_rep,\n",
        "                                     embedded), dim = 1))\n",
        "\n",
        "        return output, decoder_hidden.squeeze(0)\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self,\n",
        "                 encoder: nn.Module,\n",
        "                 decoder: nn.Module,\n",
        "                 device: torch.device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                teacher_forcing_ratio: float = 0.5) -> Tensor:\n",
        "\n",
        "        batch_size = src.shape[1]\n",
        "        max_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        # first input to the decoder is the <sos> token\n",
        "        output = trg[0,:]\n",
        "\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.max(1)[1]\n",
        "            output = (trg[t] if teacher_force else top1)\n",
        "            #print(vocab_a.lookup_token(trg[t][0].item()))\n",
        "        return outputs\n",
        "\n",
        "\n",
        "INPUT_DIM = len(vocab_q)\n",
        "OUTPUT_DIM = len(vocab_a)\n",
        "#ENC_EMB_DIM = 256\n",
        "#DEC_EMB_DIM = 256\n",
        "#ENC_HID_DIM = 512\n",
        "#DEC_HID_DIM = 512\n",
        "#ATTN_DIM = 64\n",
        "#ENC_DROPOUT = 0.5\n",
        "#DEC_DROPOUT = 0.5\n",
        "\n",
        "ENC_EMB_DIM = 32\n",
        "DEC_EMB_DIM = 32\n",
        "ENC_HID_DIM = 64\n",
        "DEC_HID_DIM = 64\n",
        "ATTN_DIM = 8\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "\n",
        "def init_weights(m: nn.Module):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "def count_parameters(model: nn.Module):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDNn4Xffg2EG",
        "outputId": "d380ab32-48fc-4595-dbf0-84c7d377ce88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "69114\n"
          ]
        }
      ],
      "source": [
        "print(OUTPUT_DIM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3BcchRDWQW0f"
      },
      "outputs": [],
      "source": [
        "PAD_IDX = vocab_a['<pad>']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1INbWQFQlv5"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import time\n",
        "\n",
        "\n",
        "def train(model: nn.Module,\n",
        "          iterator: torch.utils.data.DataLoader,\n",
        "          optimizer: optim.Optimizer,\n",
        "          criterion: nn.Module,\n",
        "          clip: float):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for _, (src, trg) in enumerate(iterator):\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model: nn.Module,\n",
        "             iterator: torch.utils.data.DataLoader,\n",
        "             criterion: nn.Module):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, (src, trg) in enumerate(iterator):\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def epoch_time(start_time: int,\n",
        "               end_time: int):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "N_EPOCHS = 1\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, val_iter, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "    torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/model.data')\n",
        "\n",
        "test_loss = evaluate(model, test_iter, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "VHPME1Wwzuu0"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/model.data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "g18GeN-tW6NG",
        "outputId": "f3802eac-7b10-4614-d033-74187b4a6b5c"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-186de0d3af87>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model = Seq2Seq(*args, **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/model.data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2042\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2043\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Seq2Seq:\n\tsize mismatch for encoder.embedding.weight: copying a param with shape torch.Size([73251, 32]) from checkpoint, the shape in current model is torch.Size([73252, 32]).\n\tsize mismatch for decoder.embedding.weight: copying a param with shape torch.Size([69113, 32]) from checkpoint, the shape in current model is torch.Size([69114, 32]).\n\tsize mismatch for decoder.out.weight: copying a param with shape torch.Size([69113, 224]) from checkpoint, the shape in current model is torch.Size([69114, 224]).\n\tsize mismatch for decoder.out.bias: copying a param with shape torch.Size([69113]) from checkpoint, the shape in current model is torch.Size([69114])."
          ]
        }
      ],
      "source": [
        "#model = Seq2Seq(*args, **kwargs)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/model.data'))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "CISIUEZIS8uG"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_response(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    tokens = question_tokenizer(sentence)\n",
        "\n",
        "\n",
        "    tokens = ['<bos>'] + tokens + ['<eos>']\n",
        "\n",
        "    src_indexes = [src_field[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    src_len = torch.LongTensor([len(src_indexes)])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_outputs, hidden = model.encoder(src_tensor)\n",
        "\n",
        "    trg_indexes = [trg_field['<bos>']]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden = model.decoder(trg_tensor, hidden, encoder_outputs)\n",
        "\n",
        "\n",
        "        pred_token = output.argmax(1).item()\n",
        "\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field['<eos>']:\n",
        "            break\n",
        "\n",
        "    trg_tokens = trg_field.lookup_tokens(trg_indexes)\n",
        "\n",
        "    return trg_tokens[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7k2ttf9f1D8",
        "outputId": "6f083562-5e86-4fee-ec51-b80d8c83b17f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['', 'i', '<eos>']"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_response('what is the command', vocab_q, vocab_a, model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install nltk\n",
        "! pip install tabulate\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "reference_translations must be testoutput\n",
        "generated_outputs must be the outputs generated by the model\n",
        "in 2dArray format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "reference_translations = [['I love cats'], ['She likes dogs']]\n",
        "generated_outputs = ['I love dogs', 'He likes cats']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "BLEU Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "reference_translations_tokenized = [[nltk.word_tokenize(sentence) for sentence in reference] for reference in reference_translations]\n",
        "generated_outputs_tokenized = [nltk.word_tokenize(sentence) for sentence in generated_outputs]\n",
        "\n",
        "bleu_score = corpus_bleu(reference_translations_tokenized, generated_outputs_tokenized)\n",
        "print(\"BLEU score:\", bleu_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Exact Match Ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "exact_match_count = sum([1 if ref == gen else 0 for ref, gen in zip(reference_translations, generated_outputs)])\n",
        "exact_match_ratio = exact_match_count / len(reference_translations) * 100\n",
        "print(\"Exact Match Ratio:\", exact_match_ratio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Word Error Rate (WER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def wer(r, h):\n",
        "    # Initialize the dynamic programming table\n",
        "    d = [[0] * (len(h) + 1) for _ in range(len(r) + 1)]\n",
        "\n",
        "    for i in range(len(r) + 1):\n",
        "        for j in range(len(h) + 1):\n",
        "            if i == 0:\n",
        "                d[i][j] = j\n",
        "            elif j == 0:\n",
        "                d[i][j] = i\n",
        "            elif r[i - 1] == h[j - 1]:\n",
        "                d[i][j] = d[i - 1][j - 1]\n",
        "            else:\n",
        "                d[i][j] = 1 + min(d[i - 1][j], d[i][j - 1], d[i - 1][j - 1])\n",
        "\n",
        "    return float(d[len(r)][len(h)]) / len(r)\n",
        "\n",
        "wer_score = wer([word for ref in reference_translations for word in nltk.word_tokenize(ref[0])],\n",
        "               [word for gen in generated_outputs for word in nltk.word_tokenize(gen)])\n",
        "print(\"Word Error Rate (WER):\", wer_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Token Precision, Recall and F1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_token_overlap(reference_tokens, generated_tokens):\n",
        "    common_tokens = set(reference_tokens) & set(generated_tokens)\n",
        "    precision = len(common_tokens) / len(generated_tokens) if len(generated_tokens) > 0 else 0\n",
        "    recall = len(common_tokens) / len(reference_tokens) if len(reference_tokens) > 0 else 0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "    return precision, recall, f1_score\n",
        "\n",
        "all_reference_tokens = [word for ref in reference_translations for word in nltk.word_tokenize(ref[0])]\n",
        "all_generated_tokens = [word for gen in generated_outputs for word in nltk.word_tokenize(gen)]\n",
        "\n",
        "precision, recall, f1_score = calculate_token_overlap(all_reference_tokens, all_generated_tokens)\n",
        "print(\"Token Precision:\", precision)\n",
        "print(\"Token Recall:\", recall)\n",
        "print(\"Token F1-score:\", f1_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "reference_translations_tokenized = [[token.lower() for token in nltk.word_tokenize(sentence)] for sentence in [ref[0] for ref in reference_translations]]\n",
        "generated_outputs_tokenized = [[token.lower() for token in nltk.word_tokenize(sentence)] for sentence in generated_outputs]\n",
        "\n",
        "# Train a Word2Vec model on a large corpus (not provided in this example)\n",
        "model = Word2Vec(sentences=reference_translations_tokenized + generated_outputs_tokenized, vector_size=100, window=5, min_count=1, sg=1)\n",
        "\n",
        "# Get word embeddings for each token in the reference translations and generated outputs\n",
        "reference_embeddings = [model.wv[token] for ref in reference_translations_tokenized for token in ref]\n",
        "generated_embeddings = [model.wv[token] for token in generated_outputs_tokenized]\n",
        "\n",
        "# Calculate the semantic similarity (cosine similarity) between the embeddings\n",
        "cosine_similarities = cosine_similarity(reference_embeddings, generated_embeddings)\n",
        "average_cosine_similarity = cosine_similarities.mean()\n",
        "\n",
        "print(\"Average Semantic Similarity (Cosine Similarity):\", average_cosine_similarity)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
