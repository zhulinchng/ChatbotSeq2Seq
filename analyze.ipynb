{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {'filename': r'data\\ubuntu dialogue\\Ubuntu-dialogue-corpus\\dialogueText.csv',\n",
    "        'question_length_threshold': 20,\n",
    "        'answer_length_threshold': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing utterances...\n",
      "Done. 1038324 utterances parsed.\n",
      "Parsing into dialogues\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1038324/1038324 [00:01<00:00, 713331.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed utterances into 346108 distinct dialogues\n",
      "There are 0 non-three-turn dialogues\n",
      "There are 346108 three-turn dialogues\n",
      "Among the three-turn dialogues, there are 18881 with <=20 question words (in threshold), and 327227 over threshold\n",
      "Among the three-turn dialogues, there are 60173 with <=20 answer words (in threshold), and 285935 over threshold\n",
      "Total Number of Dialogues Falling Within the specified Thresholds: 3821\n",
      "Getting Word Counts\n",
      "Analyse.py ceased executing at 2023-07-27 01:16:22\n",
      "Shell output logged to ./output/20230727_011535.txt\n"
     ]
    }
   ],
   "source": [
    "class Dialogue:\n",
    "    id = 0,\n",
    "    utterances = [],\n",
    "    questionCount = 0,\n",
    "    combinedQuestionWordLength = 0,\n",
    "    combinedAnswerWordLength = 0,\n",
    "    answerCount = 0\n",
    "\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "        self.utterances = []\n",
    "        self.questionCount = 0\n",
    "        self.combinedQuestionWordLength = 0\n",
    "        self.combinedAnswerWordLength = 0\n",
    "        self.answerCount = 0\n",
    "\n",
    "class Utterance:\n",
    "    text = \"\",\n",
    "    dialogueId = -1,\n",
    "    fromUser = \"\",\n",
    "    isQuestion = False,\n",
    "    isAnswer = False\n",
    "\n",
    "    def __init__(self, text, dialogueId, fromUser):\n",
    "        self.text = text\n",
    "        self.dialogueId = dialogueId\n",
    "        self.fromUser = fromUser\n",
    "        self.isQuestion = False\n",
    "        self.isAnswer = False\n",
    "\n",
    "#region Logger Setup\n",
    "\n",
    "# Log to console, and to a timestamped log file\n",
    "def Log(text):    \n",
    "    print(text)\n",
    "    with open(logFilePath, 'a') as f:\n",
    "        f.write(datetime.now().strftime(\"%H:%M:%S\") + \" \" + text + \"\\n\")\n",
    "\n",
    "#endregion\n",
    "\n",
    "#region Setup\n",
    "\n",
    "fileName = args['filename']\n",
    "questionWordThreshold = args['question_length_threshold']\n",
    "answerWordThreshold = args['answer_length_threshold']\n",
    "\n",
    "if not os.path.exists(\"./output\"):\n",
    "    os.makedirs(\"./output\")\n",
    "\n",
    "startTime = datetime.now()\n",
    "logFileName = startTime.strftime(\"%Y%m%d_%H%M%S.txt\")\n",
    "logFilePath = \"./output/{logFileName}\".format(logFileName = logFileName)\n",
    "\n",
    "totalQuestionCount = 0\n",
    "totalAnswerCount = 0\n",
    "total3TurnDialogueCount = 0\n",
    "totalNon3TurnDialogueCount = 0\n",
    "totalLTEQuestionThresholdWord3TurnDialogueCount = 0\n",
    "totalOverQuestionThresholdWord3TurnDialogueCount = 0\n",
    "totalLTEAnswerThresholdWord3TurnDialogueCount = 0\n",
    "totalOverAnswerThresholdWord3TurnDialogueCount = 0\n",
    "totalDialoguesWithinThreshold = 0\n",
    "\n",
    "df = (pd.read_csv(fileName))\n",
    "\n",
    "#endregion\n",
    "\n",
    "#region Data Handling\n",
    "\n",
    "def GetUtterances():\n",
    "    parsedUtterances = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        dialogueId = row[\"dialogueID\"]\n",
    "        # Strip .tsv from end of dialogue Id\n",
    "        dialogueId = dialogueId[0:len(dialogueId) - 4]\n",
    "\n",
    "        # Make unique id from folder and dialogue id\n",
    "        strUniqueId = \"{folderId}{dialogueId}\".format(folderId = row[\"folder\"], dialogueId = dialogueId)\n",
    "        parsedUtterances.append(Utterance(row['text'], int(strUniqueId), row['from']))\n",
    "\n",
    "    return parsedUtterances\n",
    "\n",
    "#endregion\n",
    "\n",
    "#region Data Analysis\n",
    "\n",
    "# def PerformAnalysis():\n",
    "#     Log(\"Proceeding with analysis tasks...\")\n",
    "\n",
    "#     startTime = datetime.now()\n",
    "\n",
    "#     Log(\"Commencing analysis of {commentClassDescription} class comments\".format(commentClassDescription = commentClass.description))\n",
    "\n",
    "#     for comment in tqdm(commentClass.comments):\n",
    "#         TokeniseForAnalysis(comment, commentClass)\n",
    "\n",
    "#     Log(\"Spelling corrections required for {count} words\".format(count = commentClass.correctedSpellingsCount))\n",
    "#     Log(\"Sentence count: {count}\".format(count = commentClass.sentenceCount))\n",
    "#     Log(\"Token counts - before processing: {preTokensCount}, after processing: {postTokensCount} \".format(\n",
    "#         preTokensCount = commentClass.preProcessedTokenCount, postTokensCount = commentClass.postProcessedTokenCount))\n",
    "#     Log(\"Most commonly-appearing words: {top10}\".format(top10 = Counter(commentClass.tokens).most_common(10)))\n",
    "\n",
    "#     endTime = datetime.now()\n",
    "#     secondsElapsed = str(endTime - startTime)\n",
    "#     Log(\"Finished analysing '{commentClassDescription}' class in {elapsed}\".format(\n",
    "#         commentClassDescription = commentClass.description, elapsed = secondsElapsed))\n",
    "    \n",
    "#     Log(\"Analysis complete.\")\n",
    "\n",
    "# endregion\n",
    "\n",
    "# region Program Flow\n",
    "\n",
    "Log(\"Parsing utterances...\")\n",
    "utterances:List[Utterance] = GetUtterances()\n",
    "Log(\"Done. {count} utterances parsed.\".format(count = len(utterances)))\n",
    "\n",
    "Log(\"Parsing into dialogues\")\n",
    "dialogues:List[Dialogue] = []\n",
    "dialogue = Dialogue(utterances[0].dialogueId)\n",
    "lastDialogueId = utterances[0].dialogueId\n",
    "\n",
    "for u in tqdm(utterances):\n",
    "    if u.dialogueId != lastDialogueId:\n",
    "        # Stash the current dialogue and create a new one to work with\n",
    "        dialogues.append(dialogue)\n",
    "        dialogue = Dialogue(u.dialogueId)\n",
    "\n",
    "    # NOTE: Following our meeting 26/7/23, this logic is questionable\n",
    "    if len(dialogue.utterances) == 0:\n",
    "        # must the the question, first message\n",
    "        u.isQuestion = True\n",
    "    elif len(dialogue.utterances) == 1:\n",
    "        u.isQuestion = (dialogue.utterances[0].fromUser == u.fromUser)\n",
    "        u.isAnswer = (dialogue.utterances[0].fromUser != u.fromUser)\n",
    "    else:\n",
    "        # third turn cannot be the question\n",
    "        u.isQuestion = False\n",
    "        u.isAnswer = True\n",
    "\n",
    "    dialogue.utterances.append(u)\n",
    "\n",
    "    if u.isQuestion:\n",
    "        dialogue.questionCount += 1\n",
    "        totalQuestionCount += 1\n",
    "        dialogue.combinedQuestionWordLength += len(str(u.text))\n",
    "\n",
    "    if u.isAnswer:\n",
    "        dialogue.answerCount += 1\n",
    "        totalAnswerCount += 1\n",
    "        dialogue.combinedAnswerWordLength += len(str(u.text))\n",
    "\n",
    "    lastDialogueId = u.dialogueId\n",
    "\n",
    "# now push the final dialogue we were working on\n",
    "dialogues.append(dialogue)\n",
    "\n",
    "Log(\"Parsed utterances into {count} distinct dialogues\".format(count = len(dialogues)))\n",
    "\n",
    "for dialogue in dialogues:\n",
    "    if len(dialogue.utterances) == 3:\n",
    "        total3TurnDialogueCount += 1\n",
    "        if dialogue.combinedQuestionWordLength <= questionWordThreshold:\n",
    "            totalLTEQuestionThresholdWord3TurnDialogueCount += 1\n",
    "        else:\n",
    "            totalOverQuestionThresholdWord3TurnDialogueCount += 1\n",
    "\n",
    "        if dialogue.combinedAnswerWordLength <= answerWordThreshold:\n",
    "            totalLTEAnswerThresholdWord3TurnDialogueCount += 1\n",
    "        else:\n",
    "            totalOverAnswerThresholdWord3TurnDialogueCount += 1\n",
    "\n",
    "        if dialogue.combinedQuestionWordLength <= questionWordThreshold and dialogue.combinedAnswerWordLength <= answerWordThreshold:\n",
    "            totalDialoguesWithinThreshold += 1\n",
    "    else:\n",
    "        totalNon3TurnDialogueCount += 1\n",
    "        Log(\"Non 3 Turn Dialogue found, Our Unique ID: {id}\".format(id=dialogue.id))\n",
    "\n",
    "Log(\"There are {count} non-three-turn dialogues\".format(count = totalNon3TurnDialogueCount))\n",
    "Log(\"There are {count} three-turn dialogues\".format(count = total3TurnDialogueCount))\n",
    "Log(\"Among the three-turn dialogues, there are {count} with <={threshold} question words (in threshold), and {count2} over threshold\"\n",
    "    .format(count = totalLTEQuestionThresholdWord3TurnDialogueCount, count2 = totalOverQuestionThresholdWord3TurnDialogueCount, threshold=questionWordThreshold))\n",
    "Log(\"Among the three-turn dialogues, there are {count} with <={threshold} answer words (in threshold), and {count2} over threshold\"\n",
    "    .format(count = totalLTEAnswerThresholdWord3TurnDialogueCount, count2 = totalOverAnswerThresholdWord3TurnDialogueCount, threshold=answerWordThreshold))\n",
    "Log(\"Total Number of Dialogues Falling Within the specified Thresholds: {count}\".format(count=totalDialoguesWithinThreshold))\n",
    "\n",
    "Log(\"Getting Word Counts\")\n",
    "# Note that we are given the following data from toc.csv in the ubuntu dataset, so no need to get it again\n",
    "#lines,words,characters,filename\n",
    "#9212878,91660344,996253904,dialogueText_196.csv\n",
    "#16587831,166392849,1799936480,dialogueText_301.csv\n",
    "#1038325,11035331,116070597,dialogueText.csv\n",
    "\n",
    "# Note, I used 'Counter' in my mid-module assignment to get the most popular words.\n",
    "# I think you'll need a quick and dirty spaCy tokeniser to rip the utterances list into just a flat list of words.\n",
    "# It's going to be massive, but once you've done that, you can do Counter(flatListOfWords).most_common(20) \n",
    "\n",
    "Log(\"Analyse.py ceased executing at {now}\".format(now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")))\n",
    "Log(\"Shell output logged to {file}\".format(file = logFilePath))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
