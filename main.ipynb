{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative Chatbot\n",
    "==================\n",
    "> CSCK507 Group Project: Group A\n",
    "> \n",
    "This is a generative chatbot that uses a seq2seq model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import csv\n",
    "import io\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import tarfile\n",
    "import unicodedata\n",
    "import zipfile\n",
    "from io import open\n",
    "from collections import Counter, OrderedDict\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import requests\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch import optim\n",
    "from torch.jit import script, trace\n",
    "import torchtext as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in GPU\n",
    "spacy.prefer_gpu()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "try:\n",
    "    spacy.load('en_core_web_sm')\n",
    "except LookupError:\n",
    "    print('Run: python -m spacy download en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, dir):\n",
    "    \"\"\"\n",
    "    Download file from url\n",
    "    :param url: url of file\n",
    "    :param filename: name of file\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    r = requests.get(url)\n",
    "    if url.endswith('.tar.gz'):\n",
    "        z = tarfile.open(fileobj=io.BytesIO(r.content), mode=\"r:gz\")\n",
    "        z.extractall(dir)\n",
    "        z.close()\n",
    "    elif url.endswith('.zip'):\n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        z.extractall(dir)\n",
    "    else:\n",
    "        print('Unknown file type')\n",
    "    return None\n",
    "\n",
    "def extract_zip(filename, dir):\n",
    "    \"\"\"\n",
    "    Extract zip file\n",
    "    :param filename: name of file\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    z = zipfile.ZipFile(filename)\n",
    "    z.extractall(dir)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {#'WikiQACorpus': 'https://download.microsoft.com/download/E/5/F/E5FCFCEE-7005-4814-853D-DAA7C66507E0/WikiQACorpus.zip',\n",
    "            #'Question_Answer_Dataset_v1.2': 'https://www.cs.cmu.edu/~ark/QA-data/data/Question_Answer_Dataset_v1.2.tar.gz',\n",
    "            'ubuntu-dialogue': 'data/ubuntu dialogue.zip'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ubuntu-dialogue already exists\n"
     ]
    }
   ],
   "source": [
    "# Create directory\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "# Check if data is already downloaded\n",
    "for dataset, source in datasets.items():\n",
    "    if os.path.exists('data/' + dataset):\n",
    "        print(dataset + ' already exists')\n",
    "    elif dataset == 'ubuntu-dialogue':\n",
    "        ubuntu = 'data/ubuntu dialogue'\n",
    "        if os.path.exists(source):\n",
    "            os.makedirs(ubuntu)\n",
    "            extract_zip(source, ubuntu)\n",
    "            os.remove(source)\n",
    "            print(dataset + ' extracted')\n",
    "        elif os.path.exists(ubuntu):\n",
    "            print(dataset + ' already exists')\n",
    "        else:\n",
    "            kag = 'https://www.kaggle.com/datasets/rtatman/ubuntu-dialogue-corpus/download?datasetVersionNumber=2'\n",
    "            print(f'Manually download ubuntu dialogue dataset from {kag} and place in data folder')\n",
    "    else:\n",
    "        download_file(source, 'data')\n",
    "        print(dataset + ' downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1038324, 6)\n"
     ]
    }
   ],
   "source": [
    "variants = {'small':'',\n",
    "            'medium':'_196',\n",
    "            'large':'_301'}\n",
    "ubuntufile = f'data/ubuntu dialogue/ubuntu-dialogue-corpus/dialogueText{variants[\"small\"]}.csv'\n",
    "text_df = pd.read_csv(ubuntufile)\n",
    "text_df['dialogueID'] = text_df['dialogueID'].apply(lambda x: int(x.split('.')[0]))\n",
    "print(text_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>dialogueID</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>126125</td>\n",
       "      <td>2008-04-23T14:55:00.000Z</td>\n",
       "      <td>bad_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello folks, please help me a bit with the fol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>126125</td>\n",
       "      <td>2008-04-23T14:56:00.000Z</td>\n",
       "      <td>bad_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Did I choose a bad channel? I ask because you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>126125</td>\n",
       "      <td>2008-04-23T14:57:00.000Z</td>\n",
       "      <td>lordleemo</td>\n",
       "      <td>bad_image</td>\n",
       "      <td>the second sentence is better english   and we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>64545</td>\n",
       "      <td>2009-08-01T06:22:00.000Z</td>\n",
       "      <td>mechtech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sock Puppe?t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>64545</td>\n",
       "      <td>2009-08-01T06:22:00.000Z</td>\n",
       "      <td>mechtech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WTF?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   folder  dialogueID                      date       from         to  \\\n",
       "0       3      126125  2008-04-23T14:55:00.000Z  bad_image        NaN   \n",
       "1       3      126125  2008-04-23T14:56:00.000Z  bad_image        NaN   \n",
       "2       3      126125  2008-04-23T14:57:00.000Z  lordleemo  bad_image   \n",
       "3       3       64545  2009-08-01T06:22:00.000Z   mechtech        NaN   \n",
       "4       3       64545  2009-08-01T06:22:00.000Z   mechtech        NaN   \n",
       "\n",
       "                                                text  \n",
       "0  Hello folks, please help me a bit with the fol...  \n",
       "1  Did I choose a bad channel? I ask because you ...  \n",
       "2  the second sentence is better english   and we...  \n",
       "3                                       Sock Puppe?t  \n",
       "4                                               WTF?  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview text from ubuntu dialogue dataset\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>dialogueID</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>126125</td>\n",
       "      <td>2008-04-23T14:55:00.000Z</td>\n",
       "      <td>bad_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello folks, please help me a bit with the fol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>126125</td>\n",
       "      <td>2008-04-23T14:56:00.000Z</td>\n",
       "      <td>bad_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Did I choose a bad channel? I ask because you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>126125</td>\n",
       "      <td>2008-04-23T14:57:00.000Z</td>\n",
       "      <td>lordleemo</td>\n",
       "      <td>bad_image</td>\n",
       "      <td>the second sentence is better english   and we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>64545</td>\n",
       "      <td>2009-08-01T06:22:00.000Z</td>\n",
       "      <td>mechtech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sock Puppe?t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>64545</td>\n",
       "      <td>2009-08-01T06:22:00.000Z</td>\n",
       "      <td>mechtech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WTF?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   folder  dialogueID                      date       from         to  \\\n",
       "0       3      126125  2008-04-23T14:55:00.000Z  bad_image        NaN   \n",
       "1       3      126125  2008-04-23T14:56:00.000Z  bad_image        NaN   \n",
       "2       3      126125  2008-04-23T14:57:00.000Z  lordleemo  bad_image   \n",
       "3       3       64545  2009-08-01T06:22:00.000Z   mechtech        NaN   \n",
       "4       3       64545  2009-08-01T06:22:00.000Z   mechtech        NaN   \n",
       "\n",
       "                                                text  \n",
       "0  Hello folks, please help me a bit with the fol...  \n",
       "1  Did I choose a bad channel? I ask because you ...  \n",
       "2  the second sentence is better english   and we...  \n",
       "3                                       Sock Puppe?t  \n",
       "4                                               WTF?  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce df size\n",
    "text_df = text_df[:100]\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data and structure it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm') # load spacy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodetoascii(text):\n",
    "    \"\"\"\n",
    "    Turn a Unicode string to plain ASCII\n",
    "\n",
    "    :param text: text to be converted\n",
    "    :return: text in ascii format\n",
    "    \"\"\"\n",
    "    normalized_text = unicodedata.normalize('NFKD', str(text))\n",
    "    ascii_text = ''.join(char for char in normalized_text if unicodedata.category(char) != 'Mn')\n",
    "    return ascii_text\n",
    "\n",
    "def preprocess_text(text, fn=unicodetoascii):\n",
    "\n",
    "    text = fn(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', \"\", text) # Remove non-ASCII characters\n",
    "    text = re.sub(r\"(\\w)[!?]+(\\w)\", r'\\1\\2', text) # Remove !? between words\n",
    "    text = re.sub(r\"\\s\\s+\", r\" \", text).strip() # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "def parse_dialogue(data):\n",
    "    dialogues = {}\n",
    "    df = data.copy()\n",
    "    df.reset_index(inplace=True)\n",
    "    # Group by dialogueID\n",
    "    for dialogue_id, group in df.groupby('dialogueID'):\n",
    "        sentence_pairs = {}\n",
    "        context = ''\n",
    "        previous_direction = (None, None)\n",
    "        for i, row in group.iterrows():\n",
    "            idx = row['index']\n",
    "            sender = row['from']\n",
    "            recipient = row['to']\n",
    "            response = str(row['text'])\n",
    "            direction = (sender, recipient)\n",
    "\n",
    "            if direction == previous_direction:\n",
    "                # add to the response to the previous message if the current message is consecutive\n",
    "                prev_idx = idx - 1\n",
    "                while prev_idx not in sentence_pairs:\n",
    "                    prev_idx -= 1\n",
    "                response = context + ' ' + response\n",
    "                sentence_pairs[prev_idx] = (sentence_pairs[prev_idx][0], response)\n",
    "                # sentence_pairs[-1] = (sentence_pairs[-1][0], response)\n",
    "            elif (direction == previous_direction[::-1]) or (previous_direction[1] == None) and (direction[1] == previous_direction[0]):\n",
    "                # if the current message is from the previous recipient to the previous sender\n",
    "                # if the previous message did not have a recipient, but the current message is to the previous sender\n",
    "                sentence_pairs[idx]=(context, response)\n",
    "            else:\n",
    "                sentence_pairs[idx]=(context, response)\n",
    "            \n",
    "            previous_direction = tuple(direction)\n",
    "            context = str(response) # response is the context for the next message\n",
    "        # remove the sentence pairs that does not have context but only responses\n",
    "        sentence_pairs = {k: v for k, v in sentence_pairs.items() if v[0] != ''}\n",
    "        dialogues[dialogue_id] = sentence_pairs\n",
    "\n",
    "    return dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>dialogueID</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>126125</td>\n",
       "      <td>2008-04-23T14:55:00.000Z</td>\n",
       "      <td>bad_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hello folks, please help me a bit with the fol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>126125</td>\n",
       "      <td>2008-04-23T14:56:00.000Z</td>\n",
       "      <td>bad_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>did i choose a bad channel? i ask because you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>126125</td>\n",
       "      <td>2008-04-23T14:57:00.000Z</td>\n",
       "      <td>lordleemo</td>\n",
       "      <td>bad_image</td>\n",
       "      <td>the second sentence is better english and we a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>64545</td>\n",
       "      <td>2009-08-01T06:22:00.000Z</td>\n",
       "      <td>mechtech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sock puppet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>64545</td>\n",
       "      <td>2009-08-01T06:22:00.000Z</td>\n",
       "      <td>mechtech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wtf?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   folder  dialogueID                      date       from         to  \\\n",
       "0       3      126125  2008-04-23T14:55:00.000Z  bad_image        NaN   \n",
       "1       3      126125  2008-04-23T14:56:00.000Z  bad_image        NaN   \n",
       "2       3      126125  2008-04-23T14:57:00.000Z  lordleemo  bad_image   \n",
       "3       3       64545  2009-08-01T06:22:00.000Z   mechtech        NaN   \n",
       "4       3       64545  2009-08-01T06:22:00.000Z   mechtech        NaN   \n",
       "\n",
       "                                                text  \n",
       "0  hello folks, please help me a bit with the fol...  \n",
       "1  did i choose a bad channel? i ask because you ...  \n",
       "2  the second sentence is better english and we a...  \n",
       "3                                        sock puppet  \n",
       "4                                               wtf?  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df['text'] = text_df['text'].apply(preprocess_text)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogues = parse_dialogue(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogueID</th>\n",
       "      <th>index</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16039</td>\n",
       "      <td>43</td>\n",
       "      <td>is there a way to tell ubuntu not to show icon...</td>\n",
       "      <td>can use a udev rule for it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16039</td>\n",
       "      <td>44</td>\n",
       "      <td>can use a udev rule for it</td>\n",
       "      <td>thanks :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27998</td>\n",
       "      <td>82</td>\n",
       "      <td>when i upgraded from 10.04 to 10.10, the upgra...</td>\n",
       "      <td>against the upgrade tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27998</td>\n",
       "      <td>83</td>\n",
       "      <td>against the upgrade tool</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34410</td>\n",
       "      <td>88</td>\n",
       "      <td>hints on how to get nvidia driver to work?</td>\n",
       "      <td>https://help.ubuntu.com/community/binarydriver...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialogueID  index                                            context  \\\n",
       "0       16039     43  is there a way to tell ubuntu not to show icon...   \n",
       "1       16039     44                         can use a udev rule for it   \n",
       "2       27998     82  when i upgraded from 10.04 to 10.10, the upgra...   \n",
       "3       27998     83                           against the upgrade tool   \n",
       "4       34410     88         hints on how to get nvidia driver to work?   \n",
       "\n",
       "                                            response  \n",
       "0                         can use a udev rule for it  \n",
       "1                                          thanks :)  \n",
       "2                           against the upgrade tool  \n",
       "3                                             thanks  \n",
       "4  https://help.ubuntu.com/community/binarydriver...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert nested dictionary to dataframe\n",
    "def dict_to_df(data):\n",
    "    rows = []\n",
    "    for dialogue_id, sentence_pairs in data.items():\n",
    "        for idx, pair in sentence_pairs.items():\n",
    "            rows.append([dialogue_id, idx, pair[0], pair[1]])\n",
    "    df = pd.DataFrame(rows, columns=['dialogueID', 'index', 'context', 'response'])\n",
    "    return df\n",
    "\n",
    "dialogue_df = dict_to_df(dialogues)\n",
    "dialogue_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the structured data into dataframe and index it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we will be using word vectors, lemmatization is not required. (words that are similar will have vectors that are close to each other)\n",
    "- As one of the models will be using attention, removing stop words is not required. (attention will learn to ignore them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use torch text to create vocabulary\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize text\n",
    "    :param text: text to be tokenized\n",
    "    :return: list of tokens\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in nlp.tokenizer(text)]\n",
    "\n",
    "def create_mapping(df, tokenize=tokenize):\n",
    "    \"\"\"\n",
    "    Create vocabulary mapping from context and response dataframes\n",
    "    :param df_context: context dataframe\n",
    "    :param df_response: response dataframe\n",
    "    :param tokenize: tokenization function\n",
    "    :return: vocabulary mapping\n",
    "    \"\"\"\n",
    "    # Create vocabulary mapping\n",
    "    vocab = set()\n",
    "    default_tokens = ['<pad>', '<sos>', '<eos>']\n",
    "    for context, response in zip(df['context'], df['response']):\n",
    "        vocab.update(tokenize(context))\n",
    "        vocab.update(tokenize(response))\n",
    "    for token in default_tokens:\n",
    "        vocab.add(token)\n",
    "    word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "    idx2word = {idx: word for idx, word in enumerate(vocab)}\n",
    "    return word2idx, idx2word\n",
    "\n",
    "def lookup_words(idx2word, indices):\n",
    "    \"\"\"\n",
    "    Lookup words from indices\n",
    "    :param idx2word: index to word mapping\n",
    "    :param indices: indices to be converted\n",
    "    :return: list of words\n",
    "    \"\"\"\n",
    "    return [idx2word[idx] for idx in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx, idx2word = create_mapping(dialogue_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map words to indices\n",
    "dialogue_df['context_idx'] = dialogue_df['context'].apply(lambda x: [word2idx[word] for word in tokenize(x)])\n",
    "dialogue_df['response_idx'] = dialogue_df['response'].apply(lambda x: [word2idx[word] for word in tokenize(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogueID</th>\n",
       "      <th>index</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>context_idx</th>\n",
       "      <th>response_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16039</td>\n",
       "      <td>43</td>\n",
       "      <td>is there a way to tell ubuntu not to show icon...</td>\n",
       "      <td>can use a udev rule for it</td>\n",
       "      <td>[385, 390, 142, 433, 93, 3, 210, 253, 93, 223,...</td>\n",
       "      <td>[219, 35, 142, 278, 477, 489, 228]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16039</td>\n",
       "      <td>44</td>\n",
       "      <td>can use a udev rule for it</td>\n",
       "      <td>thanks :)</td>\n",
       "      <td>[219, 35, 142, 278, 477, 489, 228]</td>\n",
       "      <td>[197, 366]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27998</td>\n",
       "      <td>82</td>\n",
       "      <td>when i upgraded from 10.04 to 10.10, the upgra...</td>\n",
       "      <td>against the upgrade tool</td>\n",
       "      <td>[77, 297, 352, 57, 395, 93, 4, 351, 122, 295, ...</td>\n",
       "      <td>[180, 122, 295, 334]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27998</td>\n",
       "      <td>83</td>\n",
       "      <td>against the upgrade tool</td>\n",
       "      <td>thanks</td>\n",
       "      <td>[180, 122, 295, 334]</td>\n",
       "      <td>[197]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34410</td>\n",
       "      <td>88</td>\n",
       "      <td>hints on how to get nvidia driver to work?</td>\n",
       "      <td>https://help.ubuntu.com/community/binarydriver...</td>\n",
       "      <td>[339, 473, 406, 93, 101, 391, 96, 93, 52, 131]</td>\n",
       "      <td>[161]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dialogueID  index                                            context  \\\n",
       "0       16039     43  is there a way to tell ubuntu not to show icon...   \n",
       "1       16039     44                         can use a udev rule for it   \n",
       "2       27998     82  when i upgraded from 10.04 to 10.10, the upgra...   \n",
       "3       27998     83                           against the upgrade tool   \n",
       "4       34410     88         hints on how to get nvidia driver to work?   \n",
       "\n",
       "                                            response  \\\n",
       "0                         can use a udev rule for it   \n",
       "1                                          thanks :)   \n",
       "2                           against the upgrade tool   \n",
       "3                                             thanks   \n",
       "4  https://help.ubuntu.com/community/binarydriver...   \n",
       "\n",
       "                                         context_idx  \\\n",
       "0  [385, 390, 142, 433, 93, 3, 210, 253, 93, 223,...   \n",
       "1                 [219, 35, 142, 278, 477, 489, 228]   \n",
       "2  [77, 297, 352, 57, 395, 93, 4, 351, 122, 295, ...   \n",
       "3                               [180, 122, 295, 334]   \n",
       "4     [339, 473, 406, 93, 101, 391, 96, 93, 52, 131]   \n",
       "\n",
       "                         response_idx  \n",
       "0  [219, 35, 142, 278, 477, 489, 228]  \n",
       "1                          [197, 366]  \n",
       "2                [180, 122, 295, 334]  \n",
       "3                               [197]  \n",
       "4                               [161]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors with sos, pad, eos tokens\n",
    "def create_tensors(df, max_len=20):\n",
    "    \"\"\"\n",
    "    Create tensors with sos, pad, eos tokens\n",
    "    :param df: dataframe with context and response\n",
    "    :param max_len: maximum length of sequence\n",
    "    :return: tensors with sos, pad, eos tokens\n",
    "    \"\"\"\n",
    "    # Create tensors\n",
    "    context_tensor = torch.zeros((len(df), max_len), dtype=torch.long)\n",
    "    response_tensor = torch.zeros((len(df), max_len), dtype=torch.long)\n",
    "    for i, (context, response) in enumerate(zip(df['context_idx'], df['response_idx'])):\n",
    "        # Trim context and response\n",
    "        if len(context) > max_len:\n",
    "            context = context[:max_len]\n",
    "        if len(response) > max_len:\n",
    "            response = response[:max_len]\n",
    "        # Add to tensor\n",
    "        context_tensor[i, :len(context)] = torch.tensor(context, dtype=torch.long)\n",
    "        response_tensor[i, :len(response)] = torch.tensor(response, dtype=torch.long)\n",
    "    return context_tensor, response_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of sequence: 128\n"
     ]
    }
   ],
   "source": [
    "# get max length of context and response\n",
    "max_len_context = max(dialogue_df['context_idx'].apply(len))\n",
    "max_len_response = max(dialogue_df['response_idx'].apply(len))\n",
    "max_len = max(max_len_context, max_len_response)\n",
    "max_len = 128\n",
    "print(f'Maximum length of sequence: {max_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42, 128]) torch.Size([42, 128])\n"
     ]
    }
   ],
   "source": [
    "context_tensor, response_tensor = create_tensors(dialogue_df, max_len=max_len)\n",
    "print(context_tensor.shape, response_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and batch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextReponseBatch:\n",
    "    def __init__(self, data):\n",
    "        transposed_data = list(zip(*data))\n",
    "        self.input = torch.stack(transposed_data[0], 0)\n",
    "        self.input_mask = (self.input != 0)\n",
    "        self.target = torch.stack(transposed_data[1], 0)\n",
    "        self.target_mask = (self.target != 0)\n",
    "\n",
    "    def pin_memory(self):\n",
    "        \"\"\"\n",
    "        Pin memory for faster data transfer to GPU\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        self.input = self.input.pin_memory()\n",
    "        self.input_mask = self.input_mask.pin_memory()\n",
    "        self.target = self.target.pin_memory()\n",
    "        self.target_mask = self.target_mask.pin_memory()\n",
    "        return self\n",
    "\n",
    "def collate_wrapper(batch):\n",
    "    \"\"\"\n",
    "    Wrapper for collate function\n",
    "    :param batch: batch of data\n",
    "    :return: ContextReponseBatch object\n",
    "    \"\"\"\n",
    "    return ContextReponseBatch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, validation, and test sets\n",
    "def split_data(context_tensor, response_tensor, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Split data into train, validation, and test sets\n",
    "    :param context_tensor: context tensor\n",
    "    :param response_tensor: response tensor\n",
    "    :param train_ratio: ratio of train set\n",
    "    :param val_ratio: ratio of validation set\n",
    "    :param test_ratio: ratio of test set\n",
    "    :return: train, validation, and test sets\n",
    "    \"\"\"\n",
    "    # Split data into train, validation, and test sets\n",
    "    dataset = TensorDataset(context_tensor, response_tensor)\n",
    "    train_size = int(train_ratio * len(dataset))\n",
    "    val_size = int(val_ratio * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "# Batch data\n",
    "def batch_data(train_set, val_set, test_set, batch_size=64, fn=collate_wrapper):\n",
    "    \"\"\"\n",
    "    Batch data\n",
    "    :param train_set: train set\n",
    "    :param val_set: validation set\n",
    "    :param test_set: test set\n",
    "    :param batch_size: batch size\n",
    "    :return: train, validation, and test loaders\n",
    "    \"\"\"\n",
    "    # Batch data\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=collate_wrapper)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True, collate_fn=collate_wrapper)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True, collate_fn=collate_wrapper)\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, validation, and test sets\n",
    "train_set, val_set, test_set = split_data(context_tensor, response_tensor)\n",
    "\n",
    "# Batch data\n",
    "train_loader, val_loader, test_loader = batch_data(train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([33, 128])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview shape of batch\n",
    "next(iter(train_loader)).input.shape # (batch_size, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 33])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader)).input.transpose(0, 1).shape # (max_len, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    \"\"\"\n",
    "    Initialize weights\n",
    "    :param m: model\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.xavier_uniform_(param.data)\n",
    "        elif 'bias' in name:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "def maskNLLLoss(inp, target, mask, device=device, pad_index=0):\n",
    "    # Define the NLLLoss criterion\n",
    "    criterion = nn.NLLLoss(reduction='mean', ignore_index=pad_index)\n",
    "\n",
    "    # Flatten the target and mask tensors for proper use with NLLLoss\n",
    "    flat_target = target.view(-1)\n",
    "    flat_mask = mask.view(-1)\n",
    "\n",
    "    # Apply the mask to the input and target tensors\n",
    "    masked_inp = inp[flat_mask]\n",
    "    masked_target = flat_target[flat_mask]\n",
    "\n",
    "    # Calculate the NLLLoss\n",
    "    loss = criterion(masked_inp, masked_target)\n",
    "\n",
    "    # Calculate the total number of non-masked elements\n",
    "    nTotal = mask.sum().item()\n",
    "\n",
    "    loss.to(device)\n",
    "\n",
    "    return loss, nTotal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 emb_dim: int,\n",
    "                 enc_hid_dim: int,\n",
    "                 dec_hid_dim: int,\n",
    "                 dropout: float = 0):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True, batch_first=False, num_layers=1)\n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)))\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self,\n",
    "                 enc_hid_dim: int,\n",
    "                 dec_hid_dim: int,\n",
    "                 attn_dim: int):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n",
    "\n",
    "        self.attn = nn.Linear(self.attn_in, attn_dim)\n",
    "\n",
    "    def forward(self,\n",
    "                decoder_hidden: torch.Tensor,\n",
    "                encoder_outputs: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        # Luong attention\n",
    "        energy = torch.tanh(self.attn(torch.cat((repeated_decoder_hidden, encoder_outputs), dim=2)))\n",
    "        attention = torch.sum(energy, dim=2)\n",
    "\n",
    "        return F.softmax(attention, dim=1)\n",
    "\n",
    "\n",
    "class AttnDecoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 output_dim: int,\n",
    "                 emb_dim: int,\n",
    "                 enc_hid_dim: int,\n",
    "                 dec_hid_dim: int,\n",
    "                 attention: nn.Module,\n",
    "                 dropout: float = 0):\n",
    "        super(AttnDecoder, self).__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.dropout = dropout\n",
    "        self.attention = attention\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim, batch_first=False, num_layers=1)\n",
    "        self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def encode_attention(self,\n",
    "                              decoder_hidden: torch.Tensor,\n",
    "                              encoder_outputs: torch.Tensor) -> torch.Tensor:\n",
    "\n",
    "        a = self.attention(decoder_hidden, encoder_outputs)\n",
    "        a = a.unsqueeze(1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
    "        weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n",
    "        return weighted_encoder_rep\n",
    "\n",
    "    def forward(self,\n",
    "                input: torch.Tensor,\n",
    "                decoder_hidden: torch.Tensor,\n",
    "                encoder_outputs: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        weighted_encoder = self.encode_attention(decoder_hidden, encoder_outputs)\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, weighted_encoder), dim=2)\n",
    "        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n",
    "\n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted_encoder = weighted_encoder.squeeze(0)\n",
    "        output = self.out(torch.cat((output, weighted_encoder, embedded), dim=1))\n",
    "        return output, decoder_hidden.squeeze(0)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 output_dim: int,\n",
    "                 emb_dim: int,\n",
    "                 enc_hid_dim: int,\n",
    "                 dec_hid_dim: int,\n",
    "                 dropout: float = 0):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim, batch_first=False, num_layers=1)\n",
    "        self.out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                input: torch.Tensor,\n",
    "                decoder_hidden: torch.Tensor,\n",
    "                encoder_outputs: torch.Tensor) -> Tuple[torch.Tensor\n",
    "                                                        , torch.Tensor]:\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        context = encoder_outputs[-1,:,:]\n",
    "        context = context.repeat(embedded.shape[0], 1, 1)\n",
    "        embs_and_context = torch.cat((embedded, context), -1)\n",
    "        output, decoder_hidden = self.rnn(embs_and_context, decoder_hidden.unsqueeze(0))\n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        context = context.squeeze(0)\n",
    "        output = self.out(torch.cat((output, embedded, context), -1))\n",
    "        return output, decoder_hidden.squeeze(0)\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,\n",
    "                 encoder: nn.Module,\n",
    "                 decoder: nn.Module,\n",
    "                 device: torch.device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self,\n",
    "                src: torch.Tensor,\n",
    "                trg: torch.Tensor,\n",
    "                teacher_forcing_ratio: float = 0.5) -> torch.Tensor:\n",
    "        src = src.transpose(0, 1) # (max_len, batch_size)\n",
    "        trg = trg.transpose(0, 1) # (max_len, batch_size)\n",
    "        batch_size = src.shape[1]\n",
    "        max_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "\n",
    "        # first input to the decoder is the <sos> token\n",
    "        output = trg[0,:]\n",
    "\n",
    "        for t in range(1, max_len):\n",
    "            output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.max(1)[1]\n",
    "            output = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([33, 128]), torch.Size([33, 128]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batch = next(iter(train_loader))\n",
    "test_batch.input.shape, test_batch.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 33, 497])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = Encoder(input_dim=len(word2idx), emb_dim=256, enc_hid_dim=512, dec_hid_dim=512)\n",
    "attn = Attention(enc_hid_dim=512, dec_hid_dim=512, attn_dim=64)\n",
    "dec = AttnDecoder(output_dim=len(word2idx), emb_dim=256, enc_hid_dim=512, dec_hid_dim=512, attention=attn)\n",
    "model = Seq2Seq(encoder=enc, decoder=dec, device=device)\n",
    "model.apply(init_weights)\n",
    "model.to(device)\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer.zero_grad()\n",
    "model(test_batch.input.to(device), test_batch.target.to(device), teacher_forcing_ratio=0.5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497\n"
     ]
    }
   ],
   "source": [
    "print(len(word2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 33, 497])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = Encoder(input_dim=len(word2idx), emb_dim=256, enc_hid_dim=512, dec_hid_dim=512)\n",
    "dec = Decoder(output_dim=len(word2idx), emb_dim=256, enc_hid_dim=512, dec_hid_dim=512)\n",
    "model = Seq2Seq(encoder=enc, decoder=dec, device=device)\n",
    "model.apply(init_weights)\n",
    "model.to(device)\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer.zero_grad()\n",
    "model(test_batch.input.to(device), test_batch.target.to(device), teacher_forcing_ratio=0.5).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function, ignoring the padding index\n",
    "PAD_INDEX = word2idx['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_INDEX)\n",
    "\n",
    "def train_model(model, train_loader, val_loader,\n",
    "                optimizer, n_epochs, max_norm=1,\n",
    "                criterion=criterion, PAD_INDEX=PAD_INDEX,\n",
    "                teacher_forcing_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Train model\n",
    "    :param model: model\n",
    "    :param train_loader: train loader\n",
    "    :param val_loader: validation loader\n",
    "    :param optimizer: optimizer\n",
    "    :param n_epochs: number of epochs\n",
    "    :param max_norm: max norm for gradient clipping\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    clip = max_norm\n",
    "    model = model.to(device)\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input = batch.input.to(device)\n",
    "            target = batch.target.to(device)\n",
    "            output = model(input, target, teacher_forcing_ratio)\n",
    "            # masked loss\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            target = target.contiguous().view(-1)\n",
    "\n",
    "            mask = (target != PAD_INDEX).float()\n",
    "            num_tokens = int(torch.sum(mask).item())\n",
    "\n",
    "            output = output[range(output.shape[0]), target] * mask\n",
    "            loss = -torch.sum(output) / num_tokens\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "        model.eval()\n",
    "        epoch_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input = batch.input.to(device)\n",
    "                target = batch.target.to(device)\n",
    "                output = model(input, target, 0)\n",
    "                output_dim = output.shape[-1]\n",
    "                output = output.contiguous().view(-1, output_dim)\n",
    "                target = target.contiguous().view(-1)\n",
    "\n",
    "                mask = (target != PAD_INDEX).float()\n",
    "                num_tokens = int(torch.sum(mask).item())\n",
    "                output = output[range(output.shape[0]), target] * mask\n",
    "                loss = -torch.sum(output) / num_tokens\n",
    "                epoch_loss += loss.item()\n",
    "        val_loss = epoch_loss / len(val_loader)\n",
    "        print(f'Epoch: {epoch+1:02} | Train Loss: {avg_train_loss:.3f} | Val Loss: {val_loss:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Train Loss: -0.046 | Val Loss: -1.173\n",
      "Epoch: 02 | Train Loss: -1.254 | Val Loss: -3.312\n",
      "Epoch: 03 | Train Loss: -3.335 | Val Loss: -8.105\n",
      "Epoch: 04 | Train Loss: -8.149 | Val Loss: -14.995\n",
      "Epoch: 05 | Train Loss: -15.267 | Val Loss: -22.629\n",
      "Epoch: 06 | Train Loss: -23.119 | Val Loss: -26.866\n",
      "Epoch: 07 | Train Loss: -27.442 | Val Loss: -29.642\n",
      "Epoch: 08 | Train Loss: -30.245 | Val Loss: -31.962\n",
      "Epoch: 09 | Train Loss: -32.755 | Val Loss: -34.010\n",
      "Epoch: 10 | Train Loss: -34.765 | Val Loss: -35.822\n"
     ]
    }
   ],
   "source": [
    "enc = Encoder(input_dim=len(word2idx), emb_dim=256, enc_hid_dim=512, dec_hid_dim=512)\n",
    "attn = Attention(enc_hid_dim=512, dec_hid_dim=512, attn_dim=64)\n",
    "dec = AttnDecoder(output_dim=len(word2idx), emb_dim=256, enc_hid_dim=512, dec_hid_dim=512, attention=attn)\n",
    "model = Seq2Seq(encoder=enc, decoder=dec, device=device)\n",
    "model.apply(init_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_model(model, train_loader, val_loader, optimizer, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate encoder, decoder\n",
    "encoder = Encoder(input_dim=len(word2idx), emb_dim=256, hid_dim=512, n_layers=2)\n",
    "attn_decoder = LuongAttnDecoderRNN(output_dim=len(word2idx), emb_dim=256, hid_dim=512, n_layers=2)\n",
    "\n",
    "# Define Seq2Seq model\n",
    "attn_model = Seq2Seq(encoder, attn_decoder, device).to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(attn_model.parameters())\n",
    "\n",
    "def train_model_attn(model, train_loader, val_loader, optimizer, n_epochs, max_norm=1):\n",
    "    model = model.to(device)\n",
    "    clip = max_norm \n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            input = batch.input.to(device)\n",
    "            target = batch.target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output, _, _ = model(input, target, 0.5) # The forward method now returns the attention weights too\n",
    "            \n",
    "            # Same as earlier, calculate loss considering mask\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            target = target.contiguous().view(-1)\n",
    "\n",
    "            mask = (target != PAD_INDEX).float()\n",
    "            num_tokens = int(torch.sum(mask).item())\n",
    "\n",
    "            output = output[range(output.shape[0]), target] * mask\n",
    "            loss = -torch.sum(output) / num_tokens\n",
    "\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping before taking the step\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            \n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "        val_loss = evaluate_model(model, val_loader)\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model_attn.pt')\n",
    "        \n",
    "        print(f'Epoch: {epoch+1:02}, Train Loss: {avg_train_loss:.3f}, Val Loss: {val_loss:.3f}')\n",
    "\n",
    "\n",
    "# Train the model\n",
    "train_model_attn(attn_model, train_loader, val_loader, optimizer, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_single_input(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = tokenize(sentence)\n",
    "    indexed = [word2idx[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).unsqueeze(0).to(device)\n",
    "    prediction = model(tensor, tensor)\n",
    "\n",
    "    predicted_idx = torch.argmax(prediction.squeeze(), dim=-1).cpu().numpy()\n",
    "    predicted_sentence = lookup_words(idx2word, predicted_idx)\n",
    "    return ' '.join(predicted_sentence)\n",
    "\n",
    "# Load the best saved model\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "test_loss = evaluate_model(model, test_loader)\n",
    "print(f'Test Loss: {test_loss:.3f}')\n",
    "\n",
    "# Test on a single sentence\n",
    "test_sentence = 'Hello, how are you today?'\n",
    "predicted_sentence = evaluate_single_input(model, test_sentence)\n",
    "print(f'Input: {test_sentence} \\nOutput: {predicted_sentence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Define training and validation split\n",
    "train_split = 0.8\n",
    "\n",
    "# Define training and validation dataset size\n",
    "train_size = int(len(dialogue_df) * train_split)\n",
    "\n",
    "# Define training and validation dataset\n",
    "train_df = dialogue_df[:train_size]\n",
    "\n",
    "# Define training and validation dataset\n",
    "val_df = dialogue_df[train_size:]\n",
    "\n",
    "# Define embedding size\n",
    "embedding_size = 300\n",
    "\n",
    "# Define hidden size\n",
    "hidden_size = 512\n",
    "\n",
    "# Define number of layers\n",
    "num_layers = 2\n",
    "\n",
    "# Define dropout\n",
    "dropout = 0.5\n",
    "\n",
    "# Define learning rate\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Define number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Define gradient clipping\n",
    "clip = 50.0\n",
    "\n",
    "# Define teacher forcing ratio\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "# Define decoder learning rate\n",
    "decoder_learning_ratio = 5.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
